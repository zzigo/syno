import { Plugin, MarkdownPostProcessorContext } from "obsidian";
import { createSin } from "./components/sin";
import { createTri } from "./components/tri";
import { createSaw } from "./components/saw";
import { createSqr } from "./components/sqr";
import { applyVol } from "./components/vol";
import { applyPan } from "./components/pan";
import { applyChop } from "./components/chop";
import { applyReverb } from "./components/reverb";

const SYNOPLUGIN_VERSION = 1.5;

export interface AudioBuffer {
    node: AudioNode;
    gain: GainNode;
    pan?: StereoPannerNode;
    duration?: number;
}

interface Ramp {
    end: number;
    duration: number;
    transition: string;
}

export default class SynoPlugin extends Plugin {
    private audioContext: AudioContext | null = null;
    private activeNodes: { osc: OscillatorNode; gain: GainNode; pan?: StereoPannerNode; interval?: NodeJS.Timeout; started?: boolean }[] = [];
    private masterGain: GainNode | null = null;

    async onload() {
        console.log(`Syno Plugin: Loaded (v${SYNOPLUGIN_VERSION})`);
        this.registerMarkdownCodeBlockProcessor("syno", (source, el, ctx) => {
            this.processSynoBlock(source, el, ctx);
        });
    }

    onunload() {
        console.log(`Syno Plugin: Unloaded (v${SYNOPLUGIN_VERSION})`);
        this.cleanupAudio();
    }

    private processSynoBlock(source: string, el: HTMLElement, ctx: MarkdownPostProcessorContext) {
        console.log("Processing Syno Block:", source);

        const container = el.createDiv({ cls: "syno-container" });
        const codeBlock = container.createEl("pre", { cls: "language-syno" });
        codeBlock.createEl("code", { cls: "language-syno", text: source });

        const controlsDiv = container.createDiv({ cls: "syno-controls" });
        controlsDiv.style.display = "flex";
        controlsDiv.style.justifyContent = "flex-end";
        controlsDiv.style.alignItems = "center";
        controlsDiv.style.marginTop = "4px";

        const vuMeter = controlsDiv.createEl("span", { text: "", cls: "syno-vumeter" });
        vuMeter.style.marginRight = "6px";

        const playButton = controlsDiv.createEl("span", { text: "▷", cls: "syno-play-button" }) as HTMLElement;
        playButton.style.cursor = "pointer";

        let isPlaying = false;

        playButton.onclick = async () => {
            if (isPlaying) {
                await this.stopSound(vuMeter, playButton);
                isPlaying = false;
            } else {
                await this.playSound(source.trim(), vuMeter, playButton);
                isPlaying = true;
            }
        };
    }

    private async playSound(input: string, vuMeter: HTMLElement, playButton: HTMLElement) {
        if (!this.audioContext) {
            this.audioContext = new AudioContext();
            await this.audioContext.resume();
        } else if (this.audioContext.state === "suspended") {
            await this.audioContext.resume();
        }

        this.cleanupAudio();

        this.masterGain = this.audioContext.createGain();
        this.masterGain.gain.value = 0.8;
        this.masterGain.connect(this.audioContext.destination);

        const lines = input.split("\n").map(line => line.trim()).filter(line => line.length > 0);
        let maxDuration = 0;

        for (const line of lines) {
            const parts = line.split(".");
            const waveType = parts[0].match(/(sin|tri|saw|sqr)/)?.[0];
            const freqInitial = parseFloat(parts[0].match(/\d+(?:\.\d+)?/)![0] || "440");

            let osc: OscillatorNode;
            switch (waveType) {
                case "tri":
                    osc = createTri(freqInitial, this.audioContext);
                    break;
                case "saw":
                    osc = createSaw(freqInitial, this.audioContext);
                    break;
                case "sqr":
                    osc = createSqr(freqInitial, this.audioContext);
                    break;
                case "sin":
                default:
                    osc = createSin(freqInitial, this.audioContext);
                    break;
            }

            const gain = this.audioContext.createGain();
            osc.connect(gain);
            let buffer: AudioBuffer = { node: gain, gain };
            let lineMaxDuration = 0;

            for (let i = 1; i < parts.length; i++) {
                const part = parts[i];

                if (part.startsWith("gliss")) {
                    const glissMatch = part.match(/gliss\((-?\d+(?:\.\d+)?),(\d+)s(?:,(linear|exp|target))?\)/);
                    if (glissMatch) {
                        const ramp: Ramp = {
                            end: parseFloat(glissMatch[1]),
                            duration: parseFloat(glissMatch[2]),
                            transition: glissMatch[3] || "linear"
                        };
                        osc.frequency.cancelScheduledValues(this.audioContext.currentTime);
                        osc.frequency.setValueAtTime(freqInitial, this.audioContext.currentTime);
                        const endTime = this.audioContext.currentTime + ramp.duration;
                        switch (ramp.transition) {
                            case "exp":
                                osc.frequency.exponentialRampToValueAtTime(Math.max(ramp.end, 0.001), endTime);
                                break;
                            case "target":
                                osc.frequency.setTargetAtTime(ramp.end, this.audioContext.currentTime, ramp.duration / 2);
                                break;
                            case "linear":
                            default:
                                osc.frequency.linearRampToValueAtTime(ramp.end, endTime);
                                break;
                        }
                        buffer.duration = ramp.duration;
                    }
                } 
                
                else if (part.startsWith("vol")) {
                    const volMatch = part.match(/vol\((-?\d+(?:\.\d+)?)(?:\s*->\s*(-?\d+(?:\.\d+)?),\s*(\d+)s(?:,\s*(linear|exp|target))?)?\)/);
                    if (volMatch) {
                        const vol = volMatch[2] ? {
                            start: parseFloat(volMatch[1]),
                            end: parseFloat(volMatch[2]),
                            duration: parseFloat(volMatch[3]),
                            transition: volMatch[4] || "linear"
                        } : parseFloat(volMatch[1]);
                        buffer = applyVol(buffer, this.audioContext, vol);
                    }
                } 

                else if (part.startsWith("pan")) {
                    const panMatch = part.match(/pan\((-?\d+(?:\.\d+)?)(?:\s*->\s*(-?\d+(?:\.\d+)?),\s*(\d+)s(?:,\s*(linear|exp|target))?)?\)/);
                    if (panMatch) {
                        const pan = panMatch[2] ? {
                            start: parseFloat(panMatch[1]),
                            end: parseFloat(panMatch[2]),
                            duration: parseFloat(panMatch[3]),
                            transition: panMatch[4] || "linear"
                        } : parseFloat(panMatch[1]);
                        buffer = applyPan(buffer, this.audioContext, pan);
                    }
                }
            }

            buffer.node.connect(this.masterGain);
            osc.start();
            this.activeNodes.push({ osc, gain: buffer.gain, pan: buffer.pan, started: true });
        }

        playButton.textContent = "■";
    }

    private async stopSound(vuMeter: HTMLElement, playButton: HTMLElement) {
        this.cleanupAudio();
        playButton.textContent = "▷";
        vuMeter.textContent = "";
    }

    private cleanupAudio() {
        this.activeNodes.forEach(({ osc, gain, pan }) => {
            try {
                osc.stop();
                osc.disconnect();
                gain.disconnect();
                if (pan) pan.disconnect();
            } catch (e) {
                console.warn("Error during cleanup:", e);
            }
        });
        this.activeNodes = [];
    }
}
